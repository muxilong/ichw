# Cache 的结构与工作原理
## 为什么要使用Cache

***

主存的速度始终低于CPU的速度，为了不降低CPU的工作效率，在CPU与主存之间加一级缓存（cache），

这样CPU可以直接从缓存中读取所需要的信息，而不必空等主存影响效率。

## 使用cache背后的原理——程序访问的局部性原理

***
　　
> Cache的出现主要解决CPU不直接访问主存， 只与高速Cache交换信息。那么，这是否可能呢?

通过大量典型程序的分析，发现CPU从主存取指令或取数据在一定时间内，只是对主存局部地址区域的访问。

这是由于指令和数据在主存内都是连续存放的，并且有些指令和数据往往会被多次调用(如子程序循环程序和一些常数).

这使得CPU在执行程序时，访存具有相对的局部性，这就叫程序访问的局部性原理。

根据这一原理，很容易设想，只要将CPU近期要用到的程序和数据， 提前从主存送到Cache， 那么就可以做到CPU在一定时间内只访问Cache。

## cache的工作原理

***

> 1.主存和缓存中的字都是按块进行存储，且缓存中的块数远小于主存中的。

详情如下：
主存由$2^n$个可编址的字组成，每个字有惟一的n位地址。

为了与Cache映射，将主存与缓存都分成若干块，每块内又包含若干个字，并使它们的块大小相同(即块内的字数相同)。

这就将主存的地址分成两段：

高m位表示主存的块地址， 低b位表示块内地址，则$2^m$＝M表示主存的块数。

同样缓存的地址也分为两段：

高c位表示缓存的块号，低b位表示块内地址，则$2^c$=C表示缓存块数，且C远小于M。

主存与缓存地址中都用b位表示其块内字数，即B=$2^b$ 反映了块的大小，称B为块长。

> 2.CPU读取数据时，会发生两种情况：命中与不命中

任何时刻都有一些主存块处在缓存块中。

CPU欲读取主存某字时，有两种可能：

一种是所需要的数已在缓存中，

即可直接访问Cache(CPU与Cache之间通常一次传送一个字)，此种情况称为CPU访问Cache命中；

另一种是所需的字不在Cache内，

此时需将该字所在的主存整个字块一次调入Cache中，此种情况称CPU访问Cache不命中。

如果主存块已调入缓存块，则称该主存块与缓存块建立了对应关系。

> 3.怎样建立对应关系？使用 tag（标记）

由于缓存的块数C远小于主存的块数M，因此，一个缓存块不能惟一地、永久地只对应一个主存块，

故每个缓存块需设一个标记用来表示当前存放的是哪一个主存块，该标记的内容相当于主存块的编号。

CPU读信息时，要将主存地址的高m位 (或m位中的一部分)与缓存块的标记进行比较，以判断所读的信息是否已在缓存中。

## cache的基本结构
***

它由Cache存储体、地址映象变换机构、Cache替换机构几大模块组成。
　　
> 1.Cache存储体。

Cache存储体以块为单位与主存交换信息，为加速Cache与主存之间的调动，主存大多采用多体结构，且Cache访存的优先级最高。

> 2.地址映象变换机构。

它将CPU送来的主存地址转换为Cache地址,进行主存的块号(高位地址)与Cache块号间的转换。

> 3.替换机构。

当Cache内容已满，无法接受来自主存块的信息时，就由Cache内的替换机构由按一定的替换算法来确定应从Cache内移出哪个块返回主存，而把新的主存块调入Cache。
